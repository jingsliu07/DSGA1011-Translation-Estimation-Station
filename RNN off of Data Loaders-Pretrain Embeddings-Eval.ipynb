{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an RNN for Machine Translation\n",
    "## Initial Data Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we will read in the data for the Vietnamese and Chinese to Engish corpuses, build a token2id and char2id mapping, vocabularies and data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an RNN for Machine Translation\n",
    "Initial Data Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "import pickle as pkl\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import io\n",
    "from collections import Counter\n",
    "import sacrebleu\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Global Variables\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in pre-trained fasttext embeddings for the three languages\n",
    "### Building loaded embeddings, token2id, id2token and ordered words for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words embedded is 100,000\n",
      "Total number of words embedded is 100,000\n",
      "Total number of words embedded is 100,000\n"
     ]
    }
   ],
   "source": [
    "# Load Pre-trained Word Vectors\n",
    "def load_embeddings(word2vec, word2id, embedding_dim):\n",
    "    embeddings = np.zeros((len(word2id), embedding_dim))\n",
    "    for word, index in word2id.items():\n",
    "        try:\n",
    "            embeddings[index] = word2vec[word]\n",
    "\n",
    "        except KeyError:\n",
    "            embeddings[index] = np.random.normal(scale=0.6, size=(300,))\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def load_vectors(fname, num_vecs=None):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "\n",
    "        if num_vecs is None:\n",
    "            pass\n",
    "        else:\n",
    "            if len(data) + 1 > num_vecs:\n",
    "                break\n",
    "    print(data.size())\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_dictionary(tokens, vocab_size_limit):\n",
    "    token_counter = Counter()\n",
    "    for token in tokens:\n",
    "        token_counter[token] += 1\n",
    "\n",
    "    vocab, count = zip(*token_counter.most_common(vocab_size_limit))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(4, 4 + len(vocab))))\n",
    "    id2token = ['<pad>', '<unk>','<sos>','<eos>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX\n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    token2id['<sos>'] = SOS_IDX\n",
    "    token2id['<eos>'] = EOS_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "#Load Word Embeddings\n",
    "\n",
    "path= '../pretrained_embeddings/'\n",
    "\n",
    "en_loaded_embeddings = load_vectors(path +'wiki.en.vec',100000)\n",
    "print(\"Total number of words embedded is {:,d}\".format(len(en_loaded_embeddings)))\n",
    "\n",
    "vi_loaded_embeddings = load_vectors(path+'wiki.vi.vec',100000)\n",
    "print(\"Total number of words embedded is {:,d}\".format(len(vi_loaded_embeddings)))\n",
    "\n",
    "zh_loaded_embeddings = load_vectors(path+'wiki.zh.vec',100000)\n",
    "print(\"Total number of words embedded is {:,d}\".format(len(zh_loaded_embeddings)))\n",
    "\n",
    "\n",
    "#Create token2Id, token2Id\n",
    "en_token2id, en_id2token = data_dictionary(list(en_loaded_embeddings.keys()), 100000)\n",
    "vi_token2id, vi_id2token = data_dictionary(list(vi_loaded_embeddings.keys()), 100000)\n",
    "zh_token2id, zh_id2token = data_dictionary(list(zh_loaded_embeddings.keys()), 100000)\n",
    "\n",
    "\n",
    "#Create Emedding Matrix\n",
    "en_loaded_embeddings=load_embeddings(en_loaded_embeddings,en_token2id,300)\n",
    "vi_loaded_embeddings=load_embeddings(vi_loaded_embeddings,vi_token2id,300)\n",
    "zh_loaded_embeddings=load_embeddings(zh_loaded_embeddings,zh_token2id,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vi -> En | Training Examples: 133317\n",
      "Vi -> En | Training Examples: 133317 \n",
      "\n",
      "Vi -> En | Validation Examples: 1268\n",
      "Vi -> En | Validation Examples: 1268 \n",
      "\n",
      "Vi -> En | Testing Examples: 1553\n",
      "Vi -> En | Testing Examples: 1553 \n",
      "\n",
      "Zh -> En | Training Examples: 213377\n",
      "Zh -> En | Training Examples: 213377 \n",
      "\n",
      "Zh -> En | Validation Examples: 1261\n",
      "Zh -> En | Validation Examples: 1261 \n",
      "\n",
      "Zh -> En | Testing Examples: 1397\n",
      "Zh -> En | Testing Examples: 1397 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading in the Vietnamese -> En datasets\n",
    "path1= '../project_data/en-vi/'\n",
    "\n",
    "train_vi_en = []\n",
    "with open(path1 +'train.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "train_vi_vi = []\n",
    "with open(path1 + 'train.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_vi_vi.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_vi_en = []\n",
    "with open(path1 + 'dev.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_vi_vi = []\n",
    "with open(path1 +'dev.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_vi_vi.append(line.strip().lower().split(' '))\n",
    "        \n",
    "test_vi_en = []\n",
    "with open(path1 +'test.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "test_vi_vi = []\n",
    "with open(path1 + 'test.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_vi_vi.append(line.strip().lower().split(' '))\n",
    "        \n",
    "        \n",
    "        \n",
    "#Loading in the Chinese -> En datasets\n",
    "path1= '../project_data/en-zh/'\n",
    "\n",
    "train_zh_en = []\n",
    "with open(path1 +'train.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "train_zh_zh = []\n",
    "with open(path1 + 'train.tok.zh') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_zh_zh.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_zh_en = []\n",
    "with open(path1 + 'dev.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_zh_zh = []\n",
    "with open(path1 +'dev.tok.zh') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_zh_zh.append(line.strip().lower().split(' '))\n",
    "        \n",
    "test_zh_en = []\n",
    "with open(path1 +'test.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "test_zh_zh = []\n",
    "with open(path1 + 'test.tok.zh') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_zh_zh.append(line.strip().lower().split(' '))\n",
    "    \n",
    "    \n",
    "#Sanity Checking\n",
    "print(\"Vi -> En | Training Examples: \"+str(len(train_vi_en)))\n",
    "print(\"Vi -> En | Training Examples: \"+str(len(train_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Vi -> En | Validation Examples: \"+str(len(val_vi_en)))\n",
    "print(\"Vi -> En | Validation Examples: \"+str(len(val_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Vi -> En | Testing Examples: \"+str(len(test_vi_en)))\n",
    "print(\"Vi -> En | Testing Examples: \"+str(len(test_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Training Examples: \"+str(len(train_zh_en)))\n",
    "print(\"Zh -> En | Training Examples: \"+str(len(train_zh_zh)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Validation Examples: \"+str(len(val_zh_en)))\n",
    "print(\"Zh -> En | Validation Examples: \"+str(len(val_zh_zh)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Testing Examples: \"+str(len(test_zh_en)))\n",
    "print(\"Zh -> En | Testing Examples: \"+str(len(test_zh_zh)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preserve original data for evaluation\n",
    "train_vi_en_orig = train_vi_en\n",
    "train_vi_vi_orig = train_vi_vi\n",
    "val_vi_en_orig = val_vi_en\n",
    "val_vi_vi_orig = val_vi_vi\n",
    "test_vi_en_orig = test_vi_en\n",
    "test_vi_vi_orig = test_vi_vi\n",
    "\n",
    "train_zh_en_orig = train_zh_en\n",
    "train_zh_zh_orig = train_zh_zh\n",
    "val_zh_en_orig = val_zh_en\n",
    "val_zh_zh_orig = val_zh_zh\n",
    "test_zh_en_orig = test_zh_en\n",
    "test_zh_zh_orig = test_zh_zh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_EN_MAX_LENGTH = int(np.percentile([len(sentence) for sentence in train_vi_en+train_vi_vi], 90))+1\n",
    "ZH_EN_MAX_LENGTH = int(np.percentile([len(sentence) for sentence in train_zh_en+train_zh_zh], 90))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_tokens(sentence, language, translator):\n",
    "    if language== 'English':\n",
    "        token2id = en_token2id\n",
    "    elif language== 'Vietnamese':\n",
    "        token2id = vi_token2id\n",
    "    elif language== 'Chinese':\n",
    "        token2id = zh_token2id\n",
    "    tokens = [token2id[token] if token in token2id else UNK_IDX for token in sentence]\n",
    "    if translator == 'vi':\n",
    "        max_len = VI_EN_MAX_LENGTH-1\n",
    "    elif translator == 'zh':\n",
    "        max_len = ZH_EN_MAX_LENGTH-1\n",
    "    tokens=tokens[:max_len]\n",
    "    return tokens\n",
    "\n",
    "def encoding_dataset(dataset, language, translator):\n",
    "    data = [encoding_tokens(tokens, language, translator) for tokens in dataset] \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vi_en = encoding_dataset(train_vi_en, 'English', 'vi')\n",
    "train_vi_vi = encoding_dataset(train_vi_vi, 'Vietnamese', 'vi')\n",
    "test_vi_en = encoding_dataset(test_vi_en, 'English', 'vi')\n",
    "test_vi_vi = encoding_dataset(test_vi_vi, 'Vietnamese', 'vi')\n",
    "val_vi_en = encoding_dataset(val_vi_en, 'English', 'vi')\n",
    "val_vi_vi = encoding_dataset(val_vi_vi, 'Vietnamese', 'vi')\n",
    "\n",
    "train_zh_en = encoding_dataset(train_zh_en, 'English', 'zh')\n",
    "train_zh_zh = encoding_dataset(train_zh_zh, 'Chinese', 'zh')\n",
    "test_zh_en = encoding_dataset(test_zh_en, 'English', 'zh')\n",
    "test_zh_zh = encoding_dataset(test_zh_zh, 'Chinese', 'zh')\n",
    "val_zh_en = encoding_dataset(val_zh_en, 'English', 'zh')\n",
    "val_zh_zh = encoding_dataset(val_zh_zh, 'Chinese', 'zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class translationDataset(Dataset):\n",
    "    def __init__(self, data_list, target_list):\n",
    "        self.data_list=data_list\n",
    "        self.target_list=target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        data = self.data_list[key][:MAX_SAMPLE_LENGTH]\n",
    "        label = self.target_list[key][:MAX_SAMPLE_LENGTH]\n",
    "        return [data, len(data), label, len(label)]\n",
    "\n",
    "def translation_collate_func(batch):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for datum in batch:\n",
    "        padded_data = np.pad(np.array(datum[0]+[EOS_IDX]), \n",
    "                                pad_width=((0,MAX_SAMPLE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_data)\n",
    "        padded_label = np.pad(np.array(datum[2]+[EOS_IDX]), \n",
    "                                pad_width=((0,MAX_SAMPLE_LENGTH-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        label_list.append(padded_label)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.from_numpy(np.array(label_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VI -> EN | dataloaders\n",
    "MAX_SAMPLE_LENGTH = VI_EN_MAX_LENGTH\n",
    "\n",
    "vi_en_train_dataset = translationDataset(train_vi_vi, train_vi_en)\n",
    "vi_en_train_loader = torch.utils.data.DataLoader(dataset=vi_en_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "vi_en_val_dataset = translationDataset(val_vi_vi, val_vi_en)\n",
    "vi_en_val_loader = torch.utils.data.DataLoader(dataset=vi_en_val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "vi_en_test_dataset = translationDataset(test_vi_vi, test_vi_en)\n",
    "vi_en_test_loader = torch.utils.data.DataLoader(dataset=vi_en_test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZH -> EN | dataloaders\n",
    "MAX_SAMPLE_LENGTH = ZH_EN_MAX_LENGTH\n",
    "\n",
    "zh_en_train_dataset = translationDataset(train_zh_zh, train_zh_en)\n",
    "zh_en_train_loader = torch.utils.data.DataLoader(dataset=zh_en_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "zh_en_val_dataset = translationDataset(val_zh_zh, val_zh_en)\n",
    "zh_en_val_loader = torch.utils.data.DataLoader(dataset=zh_en_val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "zh_en_test_dataset = translationDataset(test_zh_zh, test_zh_en)\n",
    "zh_en_test_loader = torch.utils.data.DataLoader(dataset=zh_en_test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points, string):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(points)\n",
    "    plt.title(string)\n",
    "    plt.savefig((string+'.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, language, drop_rate=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.language = language\n",
    "        if language == 'Vietnamese':\n",
    "             self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(vi_loaded_embeddings), freeze=True)\n",
    "        elif language == 'Chinese':\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(vi_loaded_embeddings), freeze=True)\n",
    "        self.gru = nn.GRU(300, hidden_size)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output = self.dropout(embedded)\n",
    "        output, hidden = self.gru(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, drop_rate=0):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(en_loaded_embeddings), freeze=True)\n",
    "        self.gru = nn.GRU(hidden_size + 300, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, len(en_token2id))\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "\n",
    "    def forward(self, input, hidden, enc_output):\n",
    "        input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input)).unsqueeze(0)\n",
    "        embedded_concat = torch.cat((embedded, enc_output), dim=2)\n",
    "        output, hidden = self.gru(embedded_concat, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_tensor = input_tensor.transpose(0,1)\n",
    "    target_tensor = target_tensor.transpose(0,1)\n",
    "    \n",
    "    max_length = input_tensor.size(0)\n",
    "    batch_size = input_tensor.size(1)\n",
    "    vocab_size = len(en_token2id)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "    encoder_outputs = encoder_output[0,0]\n",
    "\n",
    "    decoder_input = input_tensor[0,:]\n",
    "    decoder_hidden = encoder_hidden\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "    else:\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            print(decoder_input[di].item())\n",
    "            if decoder_input[di].item() == EOS_IDX:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / max_length\n",
    "\n",
    "def trainIters(loader, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    language = encoder.language\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (data, labels) in enumerate(loader):\n",
    "            input_tensor = data\n",
    "            target_tensor = labels\n",
    "    \n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses, language)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 57s (- 17m 38s) (1 10%) 272.5665\n",
      "4m 6s (- 16m 24s) (2 20%) 261.9476\n",
      "5m 46s (- 13m 29s) (3 30%) 158.4742\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-45d733928d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Vietnamese'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdecoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi_en_val_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-bcaf14514d85>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(loader, encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m--> 107\u001b[0;31m                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-bcaf14514d85>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlpclass/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlpclass/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "teacher_forcing_ratio = 0.5\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "encoder1 = EncoderRNN(hidden_size, 'Vietnamese', drop_rate = 0.1).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size).to(device)\n",
    "trainIters(vi_en_val_loader, encoder1, decoder1, n_iters=10, print_every=1,plot_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    if lang == 'Vietnamese':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in vi_token2id:\n",
    "                out.append(vi_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    elif lang == 'English':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in en_token2id:\n",
    "                out.append(en_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    elif lang == 'Chinese':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in zh_token2id:\n",
    "                out.append(zh_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    return out\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_IDX)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang):\n",
    "    with torch.no_grad():   \n",
    "        \n",
    "        #for i, (data, labels) in enumerate(vi_en_train_loader):\n",
    "        #    input_tensor = data\n",
    "        \n",
    "       \n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        max_length = input_tensor.size(0)\n",
    "        input_tensor = input_tensor.transpose(0,1)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        #print(input_length)\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        #encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "        #encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size)\n",
    "\n",
    "        #for ei in range(input_length):\n",
    "        #    encoder_output, encoder_hidden = encoder(\n",
    "        #        input_tensor)\n",
    "        #    encoder_outputs[ei] = encoder_output[0,0]\n",
    "            \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "        encoder_outputs = encoder_output[0,0]\n",
    "\n",
    "        #decoder_input = torch.tensor([[SOS_IDX]] * batch_size)\n",
    "        decoder_input = input_tensor[0,:]\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        #decoder_attentions = torch.zeros(max_length, max_length)\n",
    "                \n",
    " #       for di in range(max_length):\n",
    " #           decoder_output, decoder_hidden = decoder(\n",
    "  #             decoder_input, decoder_hidden, encoder_hidden)\n",
    "          #  print(decoder_output)\n",
    "          #  print(decoder_hidden)\n",
    "  #          topv, topi = decoder_output.topk(1, di)\n",
    "            #decoder_attentions[di] = decoder_attention.data\n",
    "  #          decoder_input = topi.squeeze().detach()\n",
    "  #          print(decoder_input[di].item())\n",
    "  #          if decoder_input[di].item()== EOS_IDX:\n",
    "  #              decoded_words.append('<EOS>')\n",
    "  #              break\n",
    "  #          else:\n",
    "  #              decoded_words.append(en_id2token[decoder_input[di].item()])\n",
    "  #          print(decoded_words)\n",
    "  #          decoder_input = decoder_input[di]\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            if decoder_input[di].item() == EOS_IDX:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(en_id2token[decoder_input[di].item()])\n",
    "                \n",
    "        return decoded_words#, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def evaluateRandomly(encoder, decoder, language, n=10):\n",
    "    for i in range(n):\n",
    "        if language == 'Vietnamese':\n",
    "            index = randint(0, len(train_vi_en_orig))\n",
    "            sentence1 = train_vi_vi_orig[index] \n",
    "            sentence2 = train_vi_en_orig[index]\n",
    "        elif language == 'Chinese':\n",
    "            index = randint(0, len(train_zh_en_orig))\n",
    "            sentence1 = train_zh_zh_orig[index]\n",
    "            sentence2 = train_zh_en_orig[index]\n",
    "        \n",
    "        print('>', sentence1)\n",
    "        print('=', sentence2)\n",
    "        output_words = evaluate(encoder, decoder, sentence1, language)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ['từ', 'này', 'có', 'nghĩa', 'là', '\"', 'sống', 'trong', 'hoà_bình', '\"', 'nhưng', 'nó', 'là', 'viết', 'tắt', 'của', '\"', 'trung_tâm', 'chỉ_huy', 'khu_vực', 'về', 'hoạt_động', 'gìn_giữ', 'hoà_bình', '\"', '.']\n",
      "= ['it', 'actually', 'means', ',', '&quot;', 'to', 'believe', 'in', 'peace', ',', '&quot;', 'but', 'the', 'acronym', 'really', 'means', 'regional', 'command', 'center', 'for', 'peacekeeping', 'operations', '.']\n",
      "< , , . <pad> , <pad> <pad> <pad> <pad> <pad> , , , <pad> dąbrowski , <pad> <pad> <pad> <pad> , <pad> <pad> <pad> <pad> , dąbrowski\n",
      "\n",
      "> ['xin', 'cám_ơn', '.']\n",
      "= ['thank', 'you', '.']\n",
      "< \n",
      "\n",
      "> ['đối_với', 'hội_hoạ', ',', 'lịch_sử', 'vô_cùng', 'cần_thiết', '.']\n",
      "= ['in', 'the', 'case', 'of', 'artwork', ',', 'the', 'history', 'is', 'special', 'indeed', '.']\n",
      "< <pad> <pad>\n",
      "\n",
      "> ['vì_vậy', 'tôi', 'bắt_đầu', 'tham_dự', 'các', 'khoá', 'học', 'nghệ_thuật', ',', 'và', 'tôi', 'học', 'được', 'cách', 'tạo', 'ra', 'tác_phẩm', 'điêu_khắc', 'mà', 'cùng', 'mang', 'đến', 'sự', 'say_mê', 'khi', 'làm_việc', 'chính_xác', 'với', 'đôi', 'tay', 'của', 'mình', 'cùng', 'với', 'sự', 'đi_lên', 'với', 'nhiều', 'loại', 'dòng', 'năng_lượng', 'logic', 'khác_nhau', 'qua', 'một', 'hệ_thống', '.']\n",
      "= ['so', ',', 'i', 'started', 'taking', 'art', 'courses', ',', 'and', 'i', 'found', 'a', 'way', 'to', 'make', 'sculpture', 'that', 'brought', 'together', 'my', 'love', 'for', 'being', 'very', 'precise', 'with', 'my', 'hands', ',', 'with', 'coming', 'up', 'with', 'different', 'kinds', 'of', 'logical', 'flows', 'of', 'energy', 'through', 'a', 'system', '.']\n",
      "< <pad> <pad> <pad> <pad> ,\n",
      "\n",
      "> ['chúng_tôi', 'nhận_định', '50', 'loại', 'máy', 'quan_trọng', 'nhất', 'mà', 'theo', 'chúng_tôi', 'cuộc_sống', 'hiện_đại', 'này', 'cần', 'để', 'tồn_tại', '-', '-', 'từ', 'máy_cày', ',', 'lò', 'bánh', 'mỳ', ',', 'máy', 'làm', 'mạch', 'điện_tử', '.']\n",
      "= ['we', '&apos;ve', 'identified', 'the', '50', 'most', 'important', 'machines', 'that', 'we', 'think', 'it', 'takes', 'for', 'modern', 'life', 'to', 'exist', '--', 'things', 'from', 'tractors', ',', 'bread', 'ovens', ',', 'circuit', 'makers', '.']\n",
      "< <pad> <pad> <pad> <pad> , <pad> <pad> <pad>\n",
      "\n",
      "> ['và', 'thêm', 'nữa', ',', 'nên', 'có', 'một', 'văn_phòng', 'công_cộng', ',', 'uỷ_ban', 'dịch_vụ', 'độc_lập', ',', 'nơi', 'điều_chỉnh', 'ngân_sách', ',', 'và', 'đặc', 'biệt', 'tài_trợ', 'ngân_sách', ',', 'tới', 'các', 'những', 'người', 'cung_cấp', 'lẻ', '.']\n",
      "= ['and', 'in', 'between', ',', 'there', 'should', 'be', 'a', 'public', 'agency', ',', 'the', 'independent', 'service', 'authority', ',', 'which', 'channels', 'public', 'money', ',', 'and', 'especially', 'donor', 'money', ',', 'to', 'the', 'retail', 'providers', '.']\n",
      "< , , samarium , <pad>\n",
      "\n",
      "> ['tôi', 'sẽ', 'đi', 'đến', 'kết_luận', 'bằng', 'việc', 'kể', 'cho', 'các', 'bạn', 'về', 'một', 'bức', 'thư_điện_tử', 'tôi', 'nhận', 'được', 'trong_khi', 'đang', 'viết', 'bài', 'diễn_thuyết', 'này', 'chỉ', 'cách', 'đây', 'một', 'tháng', 'hoặc', 'khoảng', 'chừng', 'đó', '.']\n",
      "= ['i', '&apos;m', 'going', 'to', 'conclude', 'by', 'telling', 'you', 'about', 'an', 'email', 'that', 'i', 'received', 'while', 'i', 'was', 'writing', 'this', 'talk', 'just', 'a', 'month', 'or', 'so', 'ago', '.']\n",
      "< <pad> , <pad> , <pad>\n",
      "\n",
      "> ['thậm_chí', 'thực_phẩm', 'chúng_ta', 'ăn', 'và', 'cả', 'chính_phủ', '.']\n",
      "= ['they', 'even', 'affect', 'the', 'food', 'that', 'we', 'eat', 'and', 'our', 'governments', '.']\n",
      "< <pad> <pad> <pad> investigational , <pad> <pad>\n",
      "\n",
      "> ['tôi', 'nghĩ', 'chúng_ta', 'khá', 'thông_minh', ',', 'nếu', 'so_với', 'loài', 'tinh_tinh', ',', 'nhưng', 'chúng_ta', 'không', 'đủ', 'thông_minh', 'để', 'giải_quyết', 'những', 'vấn_đề', 'khổng_lồ', 'mà', 'chúng_ta', 'đang', 'đối_mặt', ',', 'trong', 'toán_học', 'trừu_tượng', 'hay', 'trong', 'việc', 'tìm_ra', 'những', 'nền', 'kinh_tế', 'hay', 'cân_bằng', 'thế_giới', 'xung_quanh', '.']\n",
      "= ['i', 'think', 'that', 'we', '&apos;re', 'pretty', 'smart', ',', 'as', 'compared', 'to', 'chimpanzees', ',', 'but', 'we', '&apos;re', 'not', 'smart', 'enough', 'to', 'deal', 'with', 'the', 'colossal', 'problems', 'that', 'we', 'face', ',', 'either', 'in', 'abstract', 'mathematics', 'or', 'in', 'figuring', 'out', 'economies', ',', 'or', 'balancing', 'the', 'world', 'around', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> , <pad> <pad> <pad> <pad> , , <pad> , <pad> <pad> , <pad> , , <pad> <pad> <pad> , <pad> , <pad> , <pad> <pad> <pad> <pad> , , <pad> <pad> <pad> <pad> <pad> <pad> , <pad>\n",
      "\n",
      "> ['biết', 'phải', 'bắt_giữ', 'ai', ',', 'thương_lượng', 'với', 'ai', '.']\n",
      "= ['you', 'know', 'who', 'to', 'arrest', ',', 'who', 'to', 'negotiate', 'with', '.']\n",
      "< <pad> <pad> <pad> , , <pad> ,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = VI_EN_MAX_LENGTH\n",
    "evaluateRandomly(encoder1, decoder1, \"Vietnamese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
