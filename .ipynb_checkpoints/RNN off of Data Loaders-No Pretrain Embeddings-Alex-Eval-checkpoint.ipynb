{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an RNN for Machine Translation\n",
    "## Initial Data Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we will read in the data for the Vietnamese and Chinese to Engish corpuses, build a token2id and char2id mapping, vocabularies and data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an RNN for Machine Translation\n",
    "Initial Data Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "import pickle as pkl\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import seaborn as sns\n",
    "import sacrebleu\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vi -> En | Training Examples: 133317\n",
      "Vi -> En | Training Examples: 133317 \n",
      "\n",
      "Vi -> En | Validation Examples: 1268\n",
      "Vi -> En | Validation Examples: 1268 \n",
      "\n",
      "Vi -> En | Testing Examples: 1553\n",
      "Vi -> En | Testing Examples: 1553 \n",
      "\n",
      "Zh -> En | Training Examples: 213377\n",
      "Zh -> En | Training Examples: 213377 \n",
      "\n",
      "Zh -> En | Validation Examples: 1261\n",
      "Zh -> En | Validation Examples: 1261 \n",
      "\n",
      "Zh -> En | Testing Examples: 1397\n",
      "Zh -> En | Testing Examples: 1397 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading in the Vietnamese -> En datasets\n",
    "path1= '../project_data/en-vi/'\n",
    "\n",
    "train_vi_en = []\n",
    "with open(path1 +'train.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "train_vi_vi = []\n",
    "with open(path1 + 'train.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_vi_vi.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_vi_en = []\n",
    "with open(path1 + 'dev.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_vi_vi = []\n",
    "with open(path1 +'dev.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_vi_vi.append(line.strip().lower().split(' '))\n",
    "        \n",
    "test_vi_en = []\n",
    "with open(path1 +'test.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "test_vi_vi = []\n",
    "with open(path1 + 'test.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_vi_vi.append(line.strip().lower().split(' '))\n",
    "        \n",
    "        \n",
    "        \n",
    "#Loading in the Chinese -> En datasets\n",
    "path2= '../project_data/en-zh/'\n",
    "\n",
    "train_zh_en = []\n",
    "with open(path2 + 'train.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "train_zh_zh = []\n",
    "with open(path2 + 'train.tok.zh') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_zh_zh.append(line.strip().lower().split(' '))\n",
    "        \n",
    "val_zh_en = []\n",
    "with open(path2 + 'dev.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_zh_en.append(line.strip().lower().split('\\t'))\n",
    "\n",
    "val_zh_zh = []\n",
    "with open(path2 + 'dev.tok.zh') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_zh_zh.append(line.strip().lower().split(' '))\n",
    "\n",
    "test_zh_en = []\n",
    "with open(path2 +'test.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_zh_en.append(line.strip().lower().split('\\t'))\n",
    "\n",
    "test_zh_zh = []\n",
    "with open(path2 + 'test.tok.zh') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_zh_zh.append(line.strip().lower().split(' '))\n",
    "    \n",
    "    \n",
    "#Sanity Checking\n",
    "print(\"Vi -> En | Training Examples: \"+str(len(train_vi_en)))\n",
    "print(\"Vi -> En | Training Examples: \"+str(len(train_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Vi -> En | Validation Examples: \"+str(len(val_vi_en)))\n",
    "print(\"Vi -> En | Validation Examples: \"+str(len(val_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Vi -> En | Testing Examples: \"+str(len(test_vi_en)))\n",
    "print(\"Vi -> En | Testing Examples: \"+str(len(test_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Training Examples: \"+str(len(train_zh_en)))\n",
    "print(\"Zh -> En | Training Examples: \"+str(len(train_zh_zh)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Validation Examples: \"+str(len(val_zh_en)))\n",
    "print(\"Zh -> En | Validation Examples: \"+str(len(val_zh_zh)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Testing Examples: \"+str(len(test_zh_en)))\n",
    "print(\"Zh -> En | Testing Examples: \"+str(len(test_zh_zh)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preserve original data for evaluation\n",
    "train_vi_en_orig = train_vi_en\n",
    "train_vi_vi_orig = train_vi_vi\n",
    "val_vi_en_orig = val_vi_en\n",
    "val_vi_vi_orig = val_vi_vi\n",
    "test_vi_en_orig = test_vi_en\n",
    "test_vi_vi_orig = test_vi_vi\n",
    "\n",
    "train_zh_en_orig = train_zh_en\n",
    "train_zh_zh_orig = train_zh_zh\n",
    "val_zh_en_orig = val_zh_en\n",
    "val_zh_zh_orig = val_zh_zh\n",
    "test_zh_en_orig = test_zh_en\n",
    "test_zh_zh_orig = test_zh_zh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Vocab and id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(all_tokens, vocab_size):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(4,4+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>', '<sos>', '<eos>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    token2id['<sos>'] = SOS_IDX\n",
    "    token2id['<eos>'] = EOS_IDX\n",
    "    return token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_tokens = [item for sublist in train_vi_en for item in sublist]\n",
    "en_train_tokens = en_train_tokens + [item for sublist in train_zh_en for item in sublist]\n",
    "vi_train_tokens = [item for sublist in train_vi_vi for item in sublist]\n",
    "zh_train_tokens = [item for sublist in train_zh_zh for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using vocab size up to equal our pre-trained embeddings so we have comparable results\n",
    "en_token2id, en_id2token = build_vocab(en_train_tokens, 100000)\n",
    "vi_token2id, vi_id2token = build_vocab(vi_train_tokens, 100000)\n",
    "zh_token2id, zh_id2token = build_vocab(zh_train_tokens, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_EN_MAX_LENGTH = int(np.percentile([len(sentence) for sentence in train_vi_en+train_vi_vi], 90))+1\n",
    "ZH_EN_MAX_LENGTH = int(np.percentile([len(sentence) for sentence in train_zh_en+train_zh_zh], 90))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_tokens(sentence, language, translator):\n",
    "    if language== 'English':\n",
    "        token2id = en_token2id\n",
    "    elif language== 'Vietnamese':\n",
    "        token2id = vi_token2id\n",
    "    elif language== 'Chinese':\n",
    "        token2id = zh_token2id\n",
    "    tokens = [token2id[token] if token in token2id else UNK_IDX for token in sentence]\n",
    "    if translator == 'vi':\n",
    "        max_len = VI_EN_MAX_LENGTH-1\n",
    "    elif translator == 'zh':\n",
    "        max_len = ZH_EN_MAX_LENGTH-1\n",
    "    tokens=tokens[:max_len]\n",
    "    return tokens\n",
    "\n",
    "def encoding_dataset(dataset, language, translator):\n",
    "    data = [encoding_tokens(tokens, language, translator) for tokens in dataset] \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vi_en = encoding_dataset(train_vi_en, 'English', 'vi')\n",
    "train_vi_vi = encoding_dataset(train_vi_vi, 'Vietnamese', 'vi')\n",
    "test_vi_en = encoding_dataset(test_vi_en, 'English', 'vi')\n",
    "test_vi_vi = encoding_dataset(test_vi_vi, 'Vietnamese', 'vi')\n",
    "val_vi_en = encoding_dataset(val_vi_en, 'English', 'vi')\n",
    "val_vi_vi = encoding_dataset(val_vi_vi, 'Vietnamese', 'vi')\n",
    "\n",
    "train_zh_en = encoding_dataset(train_zh_en, 'English', 'zh')\n",
    "train_zh_zh = encoding_dataset(train_zh_zh, 'Chinese', 'zh')\n",
    "test_zh_en = encoding_dataset(test_zh_en, 'English', 'zh')\n",
    "test_zh_zh = encoding_dataset(test_zh_zh, 'Chinese', 'zh')\n",
    "val_zh_en = encoding_dataset(val_zh_en, 'English', 'zh')\n",
    "val_zh_zh = encoding_dataset(val_zh_zh, 'Chinese', 'zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class translationDataset(Dataset):\n",
    "    def __init__(self, data_list, target_list):\n",
    "        self.data_list=data_list\n",
    "        self.target_list=target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        data = self.data_list[key][:MAX_SAMPLE_LENGTH]\n",
    "        label = self.target_list[key][:MAX_SAMPLE_LENGTH]\n",
    "        return [data, len(data), label, len(label)]\n",
    "\n",
    "def translation_collate_func(batch):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for datum in batch:\n",
    "        padded_data = np.pad(np.array(datum[0]+[EOS_IDX]), \n",
    "                                pad_width=((0,MAX_SAMPLE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_data)\n",
    "        padded_label = np.pad(np.array(datum[2]+[EOS_IDX]), \n",
    "                                pad_width=((0,MAX_SAMPLE_LENGTH-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        label_list.append(padded_label)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.from_numpy(np.array(label_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VI -> EN | dataloaders\n",
    "MAX_SAMPLE_LENGTH = VI_EN_MAX_LENGTH\n",
    "\n",
    "vi_en_train_dataset = translationDataset(train_vi_vi, train_vi_en)\n",
    "vi_en_train_loader = torch.utils.data.DataLoader(dataset=vi_en_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "vi_en_val_dataset = translationDataset(val_vi_vi, val_vi_en)\n",
    "vi_en_val_loader = torch.utils.data.DataLoader(dataset=vi_en_val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "vi_en_test_dataset = translationDataset(test_vi_vi, test_vi_en)\n",
    "vi_en_test_loader = torch.utils.data.DataLoader(dataset=vi_en_test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZH -> EN | dataloaders\n",
    "MAX_SAMPLE_LENGTH = ZH_EN_MAX_LENGTH\n",
    "\n",
    "zh_en_train_dataset = translationDataset(train_zh_zh, train_zh_en)\n",
    "zh_en_train_loader = torch.utils.data.DataLoader(dataset=zh_en_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "zh_en_val_dataset = translationDataset(val_zh_zh, val_zh_en)\n",
    "zh_en_val_loader = torch.utils.data.DataLoader(dataset=zh_en_val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "zh_en_test_dataset = translationDataset(test_zh_zh, test_zh_en)\n",
    "zh_en_test_loader = torch.utils.data.DataLoader(dataset=zh_en_test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points, string):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(points)\n",
    "    plt.title(string)\n",
    "    plt.savefig((string+'.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, language, drop_rate=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.language = language\n",
    "        if language == 'Vietnamese':\n",
    "             self.embedding = nn.Embedding(len(vi_token2id), hidden_size)\n",
    "        elif language == 'Chinese':\n",
    "            self.embedding = nn.Embedding(len(zh_token2id), hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output = self.dropout(embedded)\n",
    "        output, hidden = self.gru(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, drop_rate=0):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(len(en_token2id), hidden_size)\n",
    "        self.gru = nn.GRU(2*hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, len(en_token2id))\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "\n",
    "    def forward(self, input, hidden, enc_output):\n",
    "        input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input)).unsqueeze(0)\n",
    "        embedded_concat = torch.cat((embedded, enc_output), dim=2)\n",
    "        output, hidden = self.gru(embedded_concat, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_tensor = input_tensor.transpose(0,1)\n",
    "    target_tensor = target_tensor.transpose(0,1)\n",
    "    \n",
    "    max_length = input_tensor.size(0)\n",
    "    batch_size = input_tensor.size(1)\n",
    "    vocab_size = len(en_token2id)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "    encoder_outputs = encoder_output[0,0]\n",
    "\n",
    "    decoder_input = input_tensor[0,:]\n",
    "    decoder_hidden = encoder_hidden\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "    else:\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input[di].item() == EOS_IDX:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / max_length\n",
    "\n",
    "def trainIters(loader, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    language = encoder.language\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (data, labels) in enumerate(loader):\n",
    "            input_tensor = data\n",
    "            target_tensor = labels\n",
    "    \n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses, language)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 49s (- 16m 28s) (1 10%) 120.9199\n",
      "3m 25s (- 13m 42s) (2 20%) 84.5919\n",
      "4m 52s (- 11m 23s) (3 30%) 108.7415\n",
      "6m 6s (- 9m 9s) (4 40%) 83.2844\n",
      "7m 19s (- 7m 19s) (5 50%) 85.9463\n",
      "8m 49s (- 5m 52s) (6 60%) 84.1298\n",
      "9m 54s (- 4m 14s) (7 70%) 26.9999\n",
      "11m 29s (- 2m 52s) (8 80%) 80.5506\n",
      "13m 1s (- 1m 26s) (9 90%) 33.5217\n",
      "15m 50s (- 0m 0s) (10 100%) 66.5617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[120.91992051866318,\n",
       " 84.59185350206162,\n",
       " 108.74154739379883,\n",
       " 83.28441942003037,\n",
       " 85.94630974663629,\n",
       " 84.12979041205513,\n",
       " 26.999864620632593,\n",
       " 80.55064527723523,\n",
       " 33.52165832519531,\n",
       " 66.56165076361762]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training Model\n",
    "teacher_forcing_ratio = 0.5\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(hidden_size, 'Vietnamese').to(device)\n",
    "decoder1 = DecoderRNN(hidden_size).to(device)\n",
    "trainIters(vi_en_val_loader, encoder1, decoder1, n_iters=10, print_every=1,plot_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    if lang == 'Vietnamese':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in vi_token2id:\n",
    "                out.append(vi_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    elif lang == 'English':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in en_token2id:\n",
    "                out.append(en_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    elif lang == 'Chinese':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in zh_token2id:\n",
    "                out.append(zh_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    return out\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_IDX)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang):\n",
    "    with torch.no_grad():   \n",
    "        \n",
    "        #for i, (data, labels) in enumerate(vi_en_train_loader):\n",
    "        #    input_tensor = data\n",
    "        \n",
    "       \n",
    "       # input_tensor = torch.tensor(sentence, dtype=torch.long).view(-1, 1)\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        max_length = input_tensor.size(0)\n",
    "        input_tensor = input_tensor.transpose(0,1)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        #print(input_length)\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        #encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "        #encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size)\n",
    "\n",
    "        #for ei in range(input_length):\n",
    "        #    encoder_output, encoder_hidden = encoder(\n",
    "        #        input_tensor)\n",
    "        #    encoder_outputs[ei] = encoder_output[0,0]\n",
    "            \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "        encoder_outputs = encoder_output[0,0]\n",
    "\n",
    "        #decoder_input = torch.tensor([[SOS_IDX]] * batch_size)\n",
    "        decoder_input = input_tensor[0,:]\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        #decoder_attentions = torch.zeros(max_length, max_length)\n",
    "                \n",
    " #       for di in range(max_length):\n",
    " #           decoder_output, decoder_hidden = decoder(\n",
    "  #             decoder_input, decoder_hidden, encoder_hidden)\n",
    "          #  print(decoder_output)\n",
    "          #  print(decoder_hidden)\n",
    "  #          topv, topi = decoder_output.topk(1, di)\n",
    "            #decoder_attentions[di] = decoder_attention.data\n",
    "  #          decoder_input = topi.squeeze().detach()\n",
    "  #          print(decoder_input[di].item())\n",
    "  #          if decoder_input[di].item()== EOS_IDX:\n",
    "  #              decoded_words.append('<EOS>')\n",
    "  #              break\n",
    "  #          else:\n",
    "  #              decoded_words.append(en_id2token[decoder_input[di].item()])\n",
    "  #          print(decoded_words)\n",
    "  #          decoder_input = decoder_input[di]\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            if decoder_input[di].item() == EOS_IDX:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(en_id2token[decoder_input[di].item()])\n",
    "                \n",
    "        return decoded_words#, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def evaluateRandomly(encoder, decoder, language, n=10):\n",
    "    for i in range(n):\n",
    "        if language == 'Vietnamese':\n",
    "            index = randint(0, len(train_vi_en_orig))\n",
    "            sentence1 = train_vi_vi_orig[index] \n",
    "            sentence2 = train_vi_en_orig[index]\n",
    "        elif language == 'Chinese':\n",
    "            index = randint(0, len(train_zh_en_orig))\n",
    "            sentence1 = train_zh_zh_orig[index]\n",
    "            sentence2 = train_zh_en_orig[index]\n",
    "        \n",
    "        print('>', sentence1)\n",
    "        print('=', sentence2)\n",
    "        output_words = evaluate(encoder, decoder, sentence1, language)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ['ban_đầu', 'chúng_tôi', 'nói', ',', 'chúng_tôi', 'có_thể', 'làm', 'gì', 'để', 'giảm', 'yếu_tố', 'này', '?']\n",
      "= ['initially', 'we', 'said', ',', 'what', 'can', 'we', 'do', 'to', 'shrink', 'the', 'fudge', 'factor', '?']\n",
      "< unfolded <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> schulman <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['câu_chuyện', 'của', 'tôi', 'bắt_đầu', 'ở', 'nước', 'anh', 'với', 'lý_lịch', 'tạm', 'trong_sạch', 'và', 'sự', 'im_lặng', 'của', 'bố_mẹ', 'là', 'người', 'nhập_cư', '.']\n",
      "= ['my', 'story', 'started', 'in', 'england', 'with', 'a', 'clean', 'slate', 'and', 'the', 'silence', 'of', 'immigrant', 'parents', '.']\n",
      "< <pad> <pad> ultrastable <pad> <pad> <pad> <pad> <pad> <pad> soaring <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> schulman <pad> <pad>\n",
      "\n",
      "> ['đúng', 'vậy', ',', 'ồn_ào', 'lắm', '.', 'họ', 'đang', 'chơi', 'nhạc', 'cho', 'người_ta', 'nhảy', 'theo', '.']\n",
      "= ['again', ',', 'it', '&apos;s', 'noisy', '.', 'they', '&apos;re', 'playing', 'for', 'dancers', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> marker <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['vậy', ',', 'có_thể', 'vấn_đề', 'ở', 'đây', 'là', '1', 'mức_độ', 'gian_lận', 'chúng_ta', 'không_thể', 'vượt_qua', 'nhưng', 'chúng_ta', 'vẫn', 'có_lợi', 'từ', 'việc', 'gian_lận', 'ở', 'mức_độ', 'thấp', 'miễn_là', 'nó', 'không', 'làm', 'thay_đổi', 'ấn_tượng', 'của', 'chúng_ta', 'về', 'chính_bản_thân', 'mình', '.']\n",
      "= ['so', ',', 'maybe', 'what', 'is', 'happening', 'is', 'that', 'there', '&apos;s', 'a', 'level', 'of', 'cheating', 'we', 'can', '&apos;t', 'go', 'over', ',', 'but', 'we', 'can', 'still', 'benefit', 'from', 'cheating', 'at', 'a', 'low', 'degree', ',', 'as', 'long', 'as', 'it', 'doesn', '&apos;t', 'change', 'our', 'impressions', 'about', 'ourselves', '.']\n",
      "< <pad> <pad> avoidance schulman <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['không', 'một', 'kinh_nghiệm', 'nào', 'trước_đây', 'có_thể', 'giúp', 'tôi', 'chuẩn_bị', 'cho', 'những', 'gì', 'xảy', 'ra', 'sau', 'đó', '.', 'bạn', 'có_thể', 'đoán', 'được', 'không', '?']\n",
      "= ['none', 'of', 'my', 'previous', 'experience', 'prepared', 'me', 'for', 'what', 'came', 'next', '.', 'can', 'you', 'guess', '?']\n",
      "< , couselor <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['đây', 'là', 'lụa', 'chọn', 'thứ_tư', 'mà', 'bạn', 'sẽ', 'nhanh_chóng', 'có', '.']\n",
      "= ['this', 'is', 'a', 'fourth', 'alternative', 'that', 'you', 'are', 'soon', 'going', 'to', 'have', '.']\n",
      "< <pad> sacrificing <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['tôi', 'đã', 'chơi', 'trong', 'hội_trường', 'disney', 'và', 'hội_trường', 'carnegie', 'và', 'những', 'nơi', 'tương_tự', '.']\n",
      "= ['i', '&apos;ve', 'played', 'the', 'disney', 'hall', 'here', 'and', 'carnegie', 'hall', 'and', 'places', 'like', 'that', '.']\n",
      "< ugandans <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['tôi', 'gặp', 'nhưng', 'người', 'lẽ_ra', 'phải', 'là', 'kẻ_thù', 'của', 'mình', 'lần', 'đầu_tiên', '.', 'và', 'chúng_tôi', 'bắt_tay', ',', 'cùng', 'uống', 'cà_phê', ',', 'cùng', 'trò_chuyện', 'vui_vẻ', 'và', 'chúng_tôi', 'nói', 'về', 'thức_ăn', ',', 'bóng_rổ', '.']\n",
      "= ['i', 'met', 'with', 'people', 'that', 'are', 'supposed', 'to', 'be', 'my', 'enemies', 'for', 'the', 'first', 'time', '.', 'and', 'we', 'just', 'shake', 'hands', ',', 'and', 'have', 'a', 'coffee', 'and', 'a', 'nice', 'discussion', ',', 'and', 'we', 'talk', 'about', 'food', 'and', 'basketball', '.']\n",
      "< ugandans\n",
      "\n",
      "> ['hãy', 'để_ý', 'là', 'chai', 'lọ', 'ở', 'đây', 'còn', 'có', 'nắp', 'đóng', '.']\n",
      "= ['notice', 'that', 'the', 'bottles', 'here', 'have', 'caps', 'on', 'them', '.']\n",
      "< <pad> <pad> beautiful <pad> <pad> <pad> <pad> schulman <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['ngay', 'bây_giờ', '-', '—', 'trước_khi', 'chúng_ta', 'bắt_đầu', '-', '-', 'điều', 'này', 'là', 'rất', 'tốt', '.', 'bạn', 'đang', 'hào_hứng', 'để', 'chơi', '.', '—', 'trước_khi', 'chúng_ta', 'bắt_đầu', ',', 'cho', 'phép', 'tôi', 'lướt', 'nhanh', 'qua', 'những', 'slides', 'trên', 'kia', ',', 'bởi_vì', 'nếu', 'bạn', 'tìm_thấy', 'hứng_thú', 'ở', 'trò_chơi', 'này', ',', 'tôi', 'muốn', 'bạn', 'biết', 'thêm', 'là', 'có', 'một_số', 'mức', 'độ', 'cao', 'cấp', 'nữa', '.']\n",
      "= ['now', '—', '—', 'before', 'we', 'get', 'started', '--', 'this', 'is', 'great', '.', 'you', '&apos;re', 'excited', 'to', 'play', '.', '—', 'before', 'we', 'get', 'started', ',', 'can', 'i', 'have', 'the', 'slides', 'back', 'up', 'here', 'really', 'quick', ',', 'because', 'if', 'you', 'get', 'good', 'at', 'this', 'game', ',', 'i', 'want', 'you', 'to', 'know', 'there', 'are', 'some', 'advanced', 'levels', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> beloved <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = VI_EN_MAX_LENGTH\n",
    "evaluateRandomly(encoder1, decoder1, \"Vietnamese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate BLEU score on corpus level\n",
    "def BLEU(encoder, decoder, language):\n",
    "    hypotheses = \"\"\n",
    "    targets = \"\"\n",
    "    if language == 'Vietnamese':\n",
    "        inputs = val_vi_vi_orig\n",
    "        labels = val_vi_en_orig\n",
    "    else:\n",
    "        inputs = val_zh_zh_orig\n",
    "        labels = val_zh_zh_orig\n",
    "        \n",
    "    for sentence in inputs:\n",
    "        output = evaluate(encoder, decoder, sentence, language)\n",
    "        for word in output:\n",
    "            hypotheses = hypotheses + \" \" + word\n",
    "\n",
    "    #targets\n",
    "    for sentence in labels:\n",
    "        for word in sentence:\n",
    "            #replace infrequent words with <unk>\n",
    "            if word in en_id2token:\n",
    "                targets = targets + \" \" + word\n",
    "            else:\n",
    "                targets = targets + \" \" + '<unk>'\n",
    "\n",
    "    # hypotheses = hypotheses + (' '.join(train_vi_vi_orig[i])) + \" \"\n",
    "    # targets = targets + (' '.join(train_vi_en_orig[i])) + \" \"\n",
    "    score = sacrebleu.corpus_bleu(hypotheses, targets)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLEU(encoder1, decoder1, 'Vietnamese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU(score=1.1599524702851073e-35, counts=[27, 1, 0, 0], totals=[360, 359, 358, 357], precisions=[7.5, 0.2785515320334262, 0.13966480446927373, 0.0700280112044818], bp=3.0680243196480763e-35, sys_len=360, ref_len=28969)\n"
     ]
    }
   ],
   "source": [
    "score = sacrebleu.corpus_bleu(hypotheses, targets)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
