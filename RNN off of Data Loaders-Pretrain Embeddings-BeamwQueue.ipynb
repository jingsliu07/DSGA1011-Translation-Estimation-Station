{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an RNN for Machine Translation\n",
    "## Initial Data Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we will read in the data for the Vietnamese and Chinese to Engish corpuses, build a token2id and char2id mapping, vocabularies and data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an RNN for Machine Translation\n",
    "Initial Data Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "import pickle as pkl\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import io\n",
    "from collections import Counter\n",
    "import sacrebleu\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Global Variables\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in pre-trained fasttext embeddings for the three languages\n",
    "### Building loaded embeddings, token2id, id2token and ordered words for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words embedded is 100,000\n",
      "Total number of words embedded is 100,000\n",
      "Total number of words embedded is 100,000\n"
     ]
    }
   ],
   "source": [
    "# Load Pre-trained Word Vectors\n",
    "def load_embeddings(word2vec, word2id, embedding_dim):\n",
    "    embeddings = np.zeros((len(word2id), embedding_dim))\n",
    "    for word, index in word2id.items():\n",
    "        try:\n",
    "            embeddings[index] = word2vec[word]\n",
    "\n",
    "        except KeyError:\n",
    "            embeddings[index] = np.random.normal(scale=0.6, size=(300,))\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def load_vectors(fname, num_vecs=None):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "\n",
    "        if num_vecs is None:\n",
    "            pass\n",
    "        else:\n",
    "            if len(data) + 1 > num_vecs:\n",
    "                break\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_dictionary(tokens, vocab_size_limit):\n",
    "    token_counter = Counter()\n",
    "    for token in tokens:\n",
    "        token_counter[token] += 1\n",
    "\n",
    "    vocab, count = zip(*token_counter.most_common(vocab_size_limit))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(4, 4 + len(vocab))))\n",
    "    id2token = ['<pad>', '<unk>','<sos>','<eos>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX\n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    token2id['<sos>'] = SOS_IDX\n",
    "    token2id['<eos>'] = EOS_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "#Load Word Embeddings\n",
    "\n",
    "path= '../pretrained_embeddings/'\n",
    "\n",
    "en_loaded_embeddings = load_vectors(path +'wiki.en.vec',100000)\n",
    "print(\"Total number of words embedded is {:,d}\".format(len(en_loaded_embeddings)))\n",
    "\n",
    "vi_loaded_embeddings = load_vectors(path+'wiki.vi.vec',100000)\n",
    "print(\"Total number of words embedded is {:,d}\".format(len(vi_loaded_embeddings)))\n",
    "\n",
    "zh_loaded_embeddings = load_vectors(path+'wiki.zh.vec',100000)\n",
    "print(\"Total number of words embedded is {:,d}\".format(len(zh_loaded_embeddings)))\n",
    "\n",
    "\n",
    "#Create token2Id, token2Id\n",
    "en_token2id, en_id2token = data_dictionary(list(en_loaded_embeddings.keys()), 100000)\n",
    "vi_token2id, vi_id2token = data_dictionary(list(vi_loaded_embeddings.keys()), 100000)\n",
    "zh_token2id, zh_id2token = data_dictionary(list(zh_loaded_embeddings.keys()), 100000)\n",
    "\n",
    "\n",
    "#Create Emedding Matrix\n",
    "en_loaded_embeddings=load_embeddings(en_loaded_embeddings,en_token2id,300)\n",
    "vi_loaded_embeddings=load_embeddings(vi_loaded_embeddings,vi_token2id,300)\n",
    "zh_loaded_embeddings=load_embeddings(zh_loaded_embeddings,zh_token2id,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vi -> En | Training Examples: 133317\n",
      "Vi -> En | Training Examples: 133317 \n",
      "\n",
      "Vi -> En | Validation Examples: 1268\n",
      "Vi -> En | Validation Examples: 1268 \n",
      "\n",
      "Vi -> En | Testing Examples: 1553\n",
      "Vi -> En | Testing Examples: 1553 \n",
      "\n",
      "Zh -> En | Training Examples: 213377\n",
      "Zh -> En | Training Examples: 213377 \n",
      "\n",
      "Zh -> En | Validation Examples: 1261\n",
      "Zh -> En | Validation Examples: 1261 \n",
      "\n",
      "Zh -> En | Testing Examples: 1397\n",
      "Zh -> En | Testing Examples: 1397 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading in the Vietnamese -> En datasets\n",
    "path1= '../project_data/en-vi/'\n",
    "\n",
    "train_vi_en = []\n",
    "with open(path1 +'train.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "train_vi_vi = []\n",
    "with open(path1 + 'train.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_vi_vi.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_vi_en = []\n",
    "with open(path1 + 'dev.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_vi_vi = []\n",
    "with open(path1 +'dev.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_vi_vi.append(line.strip().lower().split(' '))\n",
    "        \n",
    "test_vi_en = []\n",
    "with open(path1 +'test.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "test_vi_vi = []\n",
    "with open(path1 + 'test.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_vi_vi.append(line.strip().lower().split(' '))\n",
    "        \n",
    "        \n",
    "        \n",
    "#Loading in the Chinese -> En datasets\n",
    "path2= '../project_data/en-zh-processed/'\n",
    "\n",
    "train_zh_en = []\n",
    "with open(path2 +'train.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "i=0\n",
    "train_zh_zh = []\n",
    "fin = io.open(path2 +'train.tok.zh', 'r', encoding='utf-8',newline= '\\n', errors='ignore')\n",
    "for line in fin:\n",
    "    if i % 2 == 0 :\n",
    "        train_zh_zh.append(line.rstrip().split(' '))\n",
    "    i+=1 \n",
    "\n",
    "val_zh_en = []\n",
    "with open(path2 + 'dev.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "i=0\n",
    "val_zh_zh = []\n",
    "fin = io.open(path2 +'dev.tok.zh', 'r', encoding='utf-8',newline= '\\n', errors='ignore')\n",
    "for line in fin:\n",
    "    if i % 2 == 0 :\n",
    "        val_zh_zh.append(line.rstrip().split(' '))\n",
    "    i+=1\n",
    "\n",
    "test_zh_en = []\n",
    "with open(path2 +'test.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "i=0\n",
    "test_zh_zh = []\n",
    "fin = io.open(path2 +'test.tok.zh', 'r', encoding='utf-8',newline= '\\n', errors='ignore')\n",
    "for line in fin:\n",
    "    if i % 2 == 0 :\n",
    "        test_zh_zh.append(line.rstrip().split(' '))\n",
    "    i+=1\n",
    "\n",
    "#Sanity Checking\n",
    "print(\"Vi -> En | Training Examples: \"+str(len(train_vi_en)))\n",
    "print(\"Vi -> En | Training Examples: \"+str(len(train_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Vi -> En | Validation Examples: \"+str(len(val_vi_en)))\n",
    "print(\"Vi -> En | Validation Examples: \"+str(len(val_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Vi -> En | Testing Examples: \"+str(len(test_vi_en)))\n",
    "print(\"Vi -> En | Testing Examples: \"+str(len(test_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Training Examples: \"+str(len(train_zh_en)))\n",
    "print(\"Zh -> En | Training Examples: \"+str(len(train_zh_zh)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Validation Examples: \"+str(len(val_zh_en)))\n",
    "print(\"Zh -> En | Validation Examples: \"+str(len(val_zh_zh)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Testing Examples: \"+str(len(test_zh_en)))\n",
    "print(\"Zh -> En | Testing Examples: \"+str(len(test_zh_zh)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preserve original data for evaluation\n",
    "train_vi_en_orig = train_vi_en\n",
    "train_vi_vi_orig = train_vi_vi\n",
    "val_vi_en_orig = val_vi_en\n",
    "val_vi_vi_orig = val_vi_vi\n",
    "test_vi_en_orig = test_vi_en\n",
    "test_vi_vi_orig = test_vi_vi\n",
    "\n",
    "train_zh_en_orig = train_zh_en\n",
    "train_zh_zh_orig = train_zh_zh\n",
    "val_zh_en_orig = val_zh_en\n",
    "val_zh_zh_orig = val_zh_zh\n",
    "test_zh_en_orig = test_zh_en\n",
    "test_zh_zh_orig = test_zh_zh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_EN_MAX_LENGTH = int(np.percentile([len(sentence) for sentence in train_vi_en+train_vi_vi], 90))+1\n",
    "ZH_EN_MAX_LENGTH = int(np.percentile([len(sentence) for sentence in train_zh_en+train_zh_zh], 90))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_tokens(sentence, language, translator):\n",
    "    if language== 'English':\n",
    "        token2id = en_token2id\n",
    "    elif language== 'Vietnamese':\n",
    "        token2id = vi_token2id\n",
    "    elif language== 'Chinese':\n",
    "        token2id = zh_token2id\n",
    "    tokens = [token2id[token] if token in token2id else UNK_IDX for token in sentence]\n",
    "    if translator == 'vi':\n",
    "        max_len = VI_EN_MAX_LENGTH-1\n",
    "    elif translator == 'zh':\n",
    "        max_len = ZH_EN_MAX_LENGTH-1\n",
    "    tokens=tokens[:max_len]\n",
    "    return tokens\n",
    "\n",
    "def encoding_dataset(dataset, language, translator):\n",
    "    data = [encoding_tokens(tokens, language, translator) for tokens in dataset] \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vi_en = encoding_dataset(train_vi_en, 'English', 'vi')\n",
    "train_vi_vi = encoding_dataset(train_vi_vi, 'Vietnamese', 'vi')\n",
    "test_vi_en = encoding_dataset(test_vi_en, 'English', 'vi')\n",
    "test_vi_vi = encoding_dataset(test_vi_vi, 'Vietnamese', 'vi')\n",
    "val_vi_en = encoding_dataset(val_vi_en, 'English', 'vi')\n",
    "val_vi_vi = encoding_dataset(val_vi_vi, 'Vietnamese', 'vi')\n",
    "\n",
    "train_zh_en = encoding_dataset(train_zh_en, 'English', 'zh')\n",
    "train_zh_zh = encoding_dataset(train_zh_zh, 'Chinese', 'zh')\n",
    "test_zh_en = encoding_dataset(test_zh_en, 'English', 'zh')\n",
    "test_zh_zh = encoding_dataset(test_zh_zh, 'Chinese', 'zh')\n",
    "val_zh_en = encoding_dataset(val_zh_en, 'English', 'zh')\n",
    "val_zh_zh = encoding_dataset(val_zh_zh, 'Chinese', 'zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class translationDataset(Dataset):\n",
    "    def __init__(self, data_list, target_list):\n",
    "        self.data_list=data_list\n",
    "        self.target_list=target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        data = self.data_list[key][:MAX_SAMPLE_LENGTH]\n",
    "        label = self.target_list[key][:MAX_SAMPLE_LENGTH]\n",
    "        return [data, len(data), label, len(label)]\n",
    "\n",
    "def translation_collate_func(batch):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for datum in batch:\n",
    "        padded_data = np.pad(np.array(datum[0]+[EOS_IDX]), \n",
    "                                pad_width=((0,MAX_SAMPLE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_data)\n",
    "        padded_label = np.pad(np.array(datum[2]+[EOS_IDX]), \n",
    "                                pad_width=((0,MAX_SAMPLE_LENGTH-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        label_list.append(padded_label)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.from_numpy(np.array(label_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VI -> EN | dataloaders\n",
    "MAX_SAMPLE_LENGTH = VI_EN_MAX_LENGTH\n",
    "\n",
    "vi_en_train_dataset = translationDataset(train_vi_vi, train_vi_en)\n",
    "vi_en_train_loader = torch.utils.data.DataLoader(dataset=vi_en_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "vi_en_val_dataset = translationDataset(val_vi_vi, val_vi_en)\n",
    "vi_en_val_loader = torch.utils.data.DataLoader(dataset=vi_en_val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "vi_en_test_dataset = translationDataset(test_vi_vi, test_vi_en)\n",
    "vi_en_test_loader = torch.utils.data.DataLoader(dataset=vi_en_test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZH -> EN | dataloaders\n",
    "MAX_SAMPLE_LENGTH = ZH_EN_MAX_LENGTH\n",
    "\n",
    "zh_en_train_dataset = translationDataset(train_zh_zh, train_zh_en)\n",
    "zh_en_train_loader = torch.utils.data.DataLoader(dataset=zh_en_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "zh_en_val_dataset = translationDataset(val_zh_zh, val_zh_en)\n",
    "zh_en_val_loader = torch.utils.data.DataLoader(dataset=zh_en_val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "zh_en_test_dataset = translationDataset(test_zh_zh, test_zh_en)\n",
    "zh_en_test_loader = torch.utils.data.DataLoader(dataset=zh_en_test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points, string):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(points)\n",
    "    plt.title(string)\n",
    "    plt.savefig((string+'.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, language, drop_rate=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.language = language\n",
    "        if language == 'Vietnamese':\n",
    "             self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(vi_loaded_embeddings), freeze=True)\n",
    "        elif language == 'Chinese':\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(vi_loaded_embeddings), freeze=True)\n",
    "        self.gru = nn.GRU(300, hidden_size)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output = self.dropout(embedded)\n",
    "        output, hidden = self.gru(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, drop_rate=0):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(en_loaded_embeddings), freeze=True)\n",
    "        self.gru = nn.GRU(hidden_size + 300, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, len(en_token2id))\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "\n",
    "    def forward(self, input, hidden, enc_output):\n",
    "        input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input)).unsqueeze(0)\n",
    "        embedded_concat = torch.cat((embedded, enc_output), dim=2)\n",
    "        output, hidden = self.gru(embedded_concat, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_tensor = input_tensor.transpose(0,1)\n",
    "    target_tensor = target_tensor.transpose(0,1)\n",
    "    \n",
    "    max_length = input_tensor.size(0)\n",
    "    batch_size = input_tensor.size(1)\n",
    "    vocab_size = len(en_token2id)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "    encoder_outputs = encoder_output[0,0]\n",
    "\n",
    "    decoder_input = input_tensor[0,:]\n",
    "    decoder_hidden = encoder_hidden\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "    else:\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input[di].item() == EOS_IDX:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / max_length\n",
    "\n",
    "def trainIters(loader, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    language = encoder.language\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (data, labels) in enumerate(loader):\n",
    "            input_tensor = data\n",
    "            target_tensor = labels\n",
    "    \n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses, language)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n",
      "dec input torch.Size([64])\n",
      "dec embedded torch.Size([1, 64, 300])\n",
      "dec enc_output torch.Size([1, 64, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-45d733928d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Vietnamese'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdecoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi_en_val_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-127-7d76663691f5>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(loader, encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m--> 113\u001b[0;31m                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-7d76663691f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlpclass/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlpclass/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "teacher_forcing_ratio = 0.5\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "encoder1 = EncoderRNN(hidden_size, 'Vietnamese', drop_rate = 0.1).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size).to(device)\n",
    "trainIters(vi_en_val_loader, encoder1, decoder1, n_iters=10, print_every=1,plot_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beam data structure\n",
    "        \n",
    "class Beam_Node(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, Prob, length):\n",
    "        self.hidden = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordId = wordId\n",
    "        self.prob = Prob\n",
    "        self.length = length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    if lang == 'Vietnamese':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in vi_token2id:\n",
    "                out.append(vi_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    elif lang == 'English':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in en_token2id:\n",
    "                out.append(en_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    elif lang == 'Chinese':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in zh_token2id:\n",
    "                out.append(zh_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    return out\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_IDX)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam(encoder, decoder, sentence, input_lang, beam_size=3):\n",
    "    with torch.no_grad():\n",
    "        beam_size = beam_size + 1 #add extra to account for padding\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        max_length = input_tensor.size(0)\n",
    "        batch_size = max_length\n",
    "        input_tensor = input_tensor.transpose(0,1)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "        encoder_outputs = encoder_output[0,0]\n",
    "\n",
    "        decoder_input = input_tensor[0,:]\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoded_sentence = []\n",
    "\n",
    "        beam_storage = []\n",
    "        for i in range(beam_size-1):\n",
    "            beam_storage.append([])\n",
    "            \n",
    "        for di in range(max_length):\n",
    "            beams = []\n",
    "            for x in range(beam_size**2):\n",
    "                beams.append([])\n",
    "                \n",
    "            #decoder_hidden = decoder_hidden[:, di, :].unsqueeze(0)\n",
    "            #encoder_output = encoder_outputs[:, di, :].unsqueeze(1)\n",
    "\n",
    "            # starting node -  self, hidden, prevNode, wordId, prob, length\n",
    "            node = Beam_Node(decoder_hidden, None, torch.LongTensor([[SOS_IDX]]), 0, 1)\n",
    "            nodes = PriorityQueue()\n",
    "            nodes.put((-node.prob, node))\n",
    "            pqueue_size = 1\n",
    "            \n",
    "            # start beam search\n",
    "            while True:\n",
    "                # give up when sentence length too large\n",
    "                if pqueue_size > 2000: \n",
    "                    print(\"ended early\")\n",
    "                    break\n",
    "                    \n",
    "                score, node = nodes.get()\n",
    "                decoder_input = node.wordId\n",
    "                decoder_hidden = node.hidden\n",
    "                print(decoder_input.size())\n",
    "                             \n",
    "                if node.wordId[0].item() == EOS_IDX and node.prevNode != None:\n",
    "                    decoded_words.append((score, node))\n",
    "                    break\n",
    "                \n",
    "                decoder_output, decoder_hidden = decoder(decoder_input[0], decoder_hidden, encoder_output)\n",
    "                prob, idx = torch.topk(decoder_output, beam_size)\n",
    "                nextnodes = []\n",
    "                \n",
    "                for next_n in range(beam_size):\n",
    "                    decoded = idx[0][next_n].view(1, -1)\n",
    "                    p = prob[0][next_n].item()\n",
    "\n",
    "                    new_node = Beam_Node(decoder_hidden, node, decoded, node.prob + p, node.length + 1)\n",
    "                    score = new_node.prob\n",
    "                    nextnodes.append((-score, new_node))\n",
    "                                      \n",
    "                # add to queue\n",
    "                for i in range(len(nextnodes)):\n",
    "                    score, nn = nextnodes[i]\n",
    "                    nodes.put((score, nn))\n",
    "                    # increase priority queue size\n",
    "                    pqueue_size += len(nextnodes) - 1\n",
    "\n",
    "            # choose best paths and trace back\n",
    "            if len(decoded_words) == 0:\n",
    "                decoded_words = [nodes.get() for _ in range(topk)]    \n",
    "\n",
    "\n",
    "            sentence = []\n",
    "            for score, n in sorted(decoded_words, key=operator.itemgetter(0)):\n",
    "                words = []\n",
    "                words.append(en_id2token[n.wordid])\n",
    "                # get prev nodes\n",
    "                while n.prevNode != None:\n",
    "                    n = n.prevNode\n",
    "                    words.append(n.wordid)\n",
    "\n",
    "                words = words[::-1]\n",
    "                sentence.append(words)\n",
    "\n",
    "            decoded_sentence.append(sentence)   \n",
    "                    \n",
    "        return decoded_sentence              \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ['khi', 'sự_nghiệp', 'của', 'mình', 'phát_triển', ',', 'david', 'byrne', 'từ', 'chơi', 'nhạc', 'trong', 'quán', 'cbgb', 'để', 'đến', 'được', 'biểu_diễn', 'ở', 'carnegie', 'hall', '.', 'ông', 'đặt', 'ra', 'một', 'câu', 'hỏi', ':', 'địa_điểm', 'tổ_chức', 'có', 'làm_nên', 'âm_nhạc', '?', 'từ', 'tiếng', 'trống', 'ngoài_trời', 'cho', 'tới', 'những', 'buổi', 'nhạc_kịch', 'wagner', 'và', 'rồi', 'là', 'sân_khấu', 'nhạc', 'rock', ',', 'ông', 'tìm_hiểu', 'cách', 'không_gian', 'đã', 'giúp', 'thúc_đẩy', 'sáng_tạo', 'âm_nhạc', '.']\n",
      "= ['as', 'his', 'career', 'grew', ',', 'david', 'byrne', 'went', 'from', 'playing', 'cbgb', 'to', 'carnegie', 'hall', '.', 'he', 'asks', ':', 'does', 'the', 'venue', 'make', 'the', 'music', '?', 'from', 'outdoor', 'drumming', 'to', 'wagnerian', 'operas', 'to', 'arena', 'rock', ',', 'he', 'explores', 'how', 'context', 'has', 'pushed', 'musical', 'innovation', '.']\n",
      "torch.Size([1, 1])\n",
      "dec input torch.Size([1])\n",
      "dec embedded torch.Size([1, 1, 300])\n",
      "dec enc_output torch.Size([1, 63, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 2. Got 1 and 63 in dimension 1 at /Users/soumith/miniconda2/conda-bld/pytorch_1532624435833/work/aten/src/TH/generic/THTensorMath.cpp:3616",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-222c8369e4e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutput_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_beam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Vietnamese\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-287-a03a1d7cb19a>\u001b[0m in \u001b[0;36mevaluate_beam\u001b[0;34m(encoder, decoder, sentence, input_lang, beam_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mnextnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlpclass/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-7d76663691f5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, enc_output)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dec embedded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dec enc_output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0membedded_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 2. Got 1 and 63 in dimension 1 at /Users/soumith/miniconda2/conda-bld/pytorch_1532624435833/work/aten/src/TH/generic/THTensorMath.cpp:3616"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "index = randint(0, len(train_vi_en_orig))\n",
    "sentence1 = train_vi_vi_orig[index] \n",
    "sentence2 = train_vi_en_orig[index]            \n",
    "\n",
    "print('>', sentence1)\n",
    "print('=', sentence2)\n",
    "output_words = evaluate_beam(encoder1, decoder1, sentence1, \"Vietnamese\")\n",
    "output_sentence = ' '.join(output_words)\n",
    "print('<', output_sentence)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def evaluateRandomly(encoder, decoder, language, n=10):\n",
    "    for i in range(n):\n",
    "        if language == 'Vietnamese':\n",
    "            index = randint(0, len(train_vi_en_orig))\n",
    "            sentence1 = train_vi_vi_orig[index] \n",
    "            sentence2 = train_vi_en_orig[index]\n",
    "        elif language == 'Chinese':\n",
    "            index = randint(0, len(train_zh_en_orig))\n",
    "            sentence1 = train_zh_zh_orig[index]\n",
    "            sentence2 = train_zh_en_orig[index]\n",
    "        \n",
    "        print('>', sentence1)\n",
    "        print('=', sentence2)\n",
    "        output_words = evaluate(encoder, decoder, sentence1, language)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ['chong_chóng', 'quay', 'là', 'một', '\"', 'đặc_tính', 'hợp', 'trội', '\"', 'xảy_ra', 'do', 'tương_tác', 'giữa', 'những', 'chú', 'chó', 'con', 'mà', 'quy_luật', 'duy_nhất', 'là', 'cố_gắng', 'duy_trì', 'sự', 'tiếp_cận', 'của', 'chúng', 'với', 'tô', 'sữa', '.', 'và', 'do', 'đó', ',', 'đẩy', 'chúng', 'đi', 'theo', 'một', 'hướng', 'ngẫu_nhiên', '.']\n",
      "= ['the', 'pinwheel', 'is', 'an', 'emergent', 'property', 'of', 'the', 'interactions', 'between', 'puppies', 'whose', 'only', 'rule', 'is', 'to', 'try', 'to', 'keep', 'access', 'to', 'the', 'milk', 'and', 'therefore', 'to', 'push', 'in', 'a', 'random', 'direction', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['sally', 'tiếp_lời', ':', '\"', 'cho', 'sự_kiện', 'mùa_hè', 'ở', 'trường', 'nyu.', '\"']\n",
      "= ['sally', ':', '&quot;', 'for', 'this', 'summer', 'program', 'at', 'nyu', '.', '&quot;']\n",
      "< \n",
      "\n",
      "> ['như', 'một', 'câu_nói', ',', 'họ', 'biết', 'rằng', '\"', 'tính_cách', 'thực_sự', 'của', 'bạn', 'đang', 'lẩn_khuất', 'trong', 'bóng_tối', '.', '\"']\n",
      "= ['they', 'know', ',', 'as', 'someone', 'once', 'said', ',', '&quot;', 'character', '&apos;s', 'who', 'you', 'are', 'in', 'the', 'dark', '.', '&quot;']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['sau', 'trải', 'niệm', 'này', ',', 'thầy_giáo', 'của', 'tôi', ',', 'thầy', 'shilale', ',', 'đã', 'mang', 'những', 'quyển', 'chuyện', 'hình', 'này', ',', 'và', 'tôi', 'nghĩ', ':', '\"', 'chuyện', 'hình', 'cho', 'trẻ_em', '!', '\"']\n",
      "= ['so', 'after', 'this', 'experience', ',', 'my', 'art', 'teacher', ',', 'mr.', 'shilale', ',', 'he', 'brought', 'in', 'these', 'picture', 'books', ',', 'and', 'i', 'thought', ',', '&quot;', 'picture', 'books', 'for', 'kids', '!', '&quot;']\n",
      "< \n",
      "\n",
      "> ['con', 'muốn', 'người', 'lan', 'rộng', 'sự', 'nổi_tiếng', 'của', 'con', 'qua', 'mọi', 'vùng', 'miền', '.']\n",
      "= ['i', 'want', 'you', 'to', 'spread', 'the', 'fame', 'of', 'my', 'name', 'through', 'every', 'land', '.']\n",
      "< \n",
      "\n",
      "> ['và', 'thế_kỷ', 'thứ', '13', ',', 'có', 'nhiều', 'hàng', 'hơn', 'và', 'những', 'hình_dáng', 'mới', 'của', 'nốt_nhạc', 'được', 'khoá', 'lại', 'trong', 'khái_niệm', 'của', 'giai_điệu', 'một_cách', 'chính_xác', ',', 'và', 'điều', 'này', 'dẫn', 'đến', 'việc', 'hình_thành', 'nên', 'những', 'nốt_nhạc', 'mà', 'chúng_ta', 'có', 'ngày_nay', '.']\n",
      "= ['and', 'then', 'in', 'the', '13th', 'century', ',', 'more', 'lines', 'and', 'new', 'shapes', 'of', 'notes', 'locked', 'in', 'the', 'concept', 'of', 'the', 'tune', 'exactly', ',', 'and', 'that', 'led', 'to', 'the', 'kind', 'of', 'notation', 'we', 'have', 'today', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> cahokia <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['nó', 'là', 'một', 'loài', 'sinh_vật', 'rất', 'cô_độc', '.']\n",
      "= ['it', '&apos;s', 'a', 'very', 'solitary', 'creature', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['một', 'bên', ',', 'chúng_ta', 'có', '1,2', 'kg', ',', 'và', 'mặt', 'kia', 'là', '0,6', 'kg', '.']\n",
      "= ['at', 'the', 'one', 'hand', ',', 'we', 'have', '1.2', 'kilos', ',', 'and', 'at', 'the', 'other', 'hand', '0.6', 'kilos', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['với', 'một', 'tâm_trạng', 'không', 'vui', '.', 'hãy', 'nghĩ', 'về', 'điều', 'này', '.']\n",
      "= ['she', '&apos;s', 'not', 'amused', '.', 'let', '&apos;s', 'think', 'about', 'it', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['nhưng', 'may_thay', ',', 'có', 'một', 'số_ít', ',', 'một_số', 'đáng', 'tự_hào', '-', 'như', 'chị', 'đây', 'khuyên', 'tôi', 'nên', 'có', 'bài', 'nói', 'như', 'vậy', '.', 'và', 'tôi', 'hỏi', 'bản_thân', ',', 'câu_hỏi', 'mà', 'mark', 'zuckerberg', 'người', 'sáng_lập', 'ra', 'facebook', 'và', 'cũng', 'là', 'sếp', 'của', 'tôi', ',', 'đã', 'hỏi', 'tất_cả', 'chúng_tôi', ',', 'rằng', ',', 'tôi', 'sẽ', 'làm', 'gì', 'nếu_không', 'cảm_thấy', 'sợ_hãi', '.']\n",
      "= ['but', 'fortunately', ',', 'there', 'were', 'the', 'few', ',', 'the', 'proud', '--', 'like', 'you', '--', 'who', 'told', 'me', 'i', 'should', 'give', 'the', 'speech', ',', 'and', 'i', 'asked', 'myself', 'the', 'question', 'mark', 'zuckerberg', 'might', '--', 'the', 'founder', 'of', 'facebook', 'and', 'my', 'boss', '--', 'asks', 'all', 'of', 'us', ',', 'which', 'is', ',', 'what', 'would', 'i', 'do', 'if', 'i', 'wasn', '&apos;t', 'afraid', '?']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = VI_EN_MAX_LENGTH\n",
    "evaluateRandomly(encoder1, decoder1, \"Vietnamese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate BLEU score on corpus level\n",
    "def BLEU(encoder, decoder, language):\n",
    "    hypotheses = \"\"\n",
    "    targets = \"\"\n",
    "    if language == 'Vietnamese':\n",
    "        inputs = val_vi_vi_orig\n",
    "        labels = val_vi_en_orig\n",
    "    else:\n",
    "        inputs = val_zh_zh_orig\n",
    "        labels = val_zh_zh_orig\n",
    "        \n",
    "    for sentence in inputs:\n",
    "        output = evaluate(encoder, decoder, sentence, language)\n",
    "        for word in output:\n",
    "            hypotheses = hypotheses + \" \" + word\n",
    "\n",
    "    #targets\n",
    "    for sentence in labels:\n",
    "        for word in sentence:\n",
    "            if word in en_id2token:\n",
    "                targets = targets + \" \" + word\n",
    "            else:\n",
    "                targets = targets + \" \" + '<unk>'\n",
    "\n",
    "    score = sacrebleu.corpus_bleu(hypotheses, targets)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU(score=0.020322293857056525, counts=[2273, 50, 1, 0], totals=[75975, 75974, 75973, 75972], precisions=[2.9917736097400462, 0.06581198831179087, 0.0013162570913350796, 0.0006581372084452166], bp=1.0, sys_len=75975, ref_len=29000)\n"
     ]
    }
   ],
   "source": [
    "BLEU(encoder1, decoder1, 'Vietnamese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
